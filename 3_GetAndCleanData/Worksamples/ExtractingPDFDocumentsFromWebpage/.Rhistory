cbind(patients, my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames <- c("patient", "age", "weight", "by", "rating", "test")
cnames <- c("patient", "age", "weight", "bp", "rating", "test")
colnames(my_data)
colnames(my_data) <- cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE
6 == 7
6 < 7
10 <= 10
5 != 7
5 != 7
!(5 == 7)
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && C(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE ""
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 >3.9
isTRUE(6 > 4)
identtical('twins', 'twins')
identical('twins', 'twins')
identical('hello', 'hello', 'hello')
identical('hello', 'hello')
xor(5 == 6, !FALSE)
ints <- sample(10)
ints
sample(2, size=20, replace=TRUE, prob=ratio)
ratio <- c(0.7, 0.3)
sample(2, size=20, replace=TRUE, prob=ratio)
s <- sample(2, size=20, replace=TRUE, prob=ratio)
sum(s[1])
sum(s[s==1])
sum(s[s==1])/length(s)
s <- sample(2, size=50, replace=TRUE, prob=ratio)
sum(s[s==1])/length(s)
paste("The ratio of 1 in this sample is :",sum(s[s==1])/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2]/length(s)))
paste("The ratio of 1 in this sample is :",sum(s[s==1])/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2]/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2]/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2]/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2])/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2])/length(s))
ratio <- c(0.7, 0.3)
s <- sample(2, size=50, replace=TRUE, prob=ratio)
paste("The ratio of 1 in this sample is :",sum(s[s==1])/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2])/length(s))
sum(s[s==1])
sum(s[s==2])
sum(s[s==1]) + sum(s[s==2])
s <- sample(2, size=50, replace=FALSE, prob=ratio)
paste("The ratio of 1 in this sample is :",sum(s[s==1])/length(s))
paste("The ratio of 2 in this sample is :", sum(s[s==2])/length(s))
sum(s[s==1]) + sum(s[s==2])
ratio <- c(0.7, 0.3)
s <- sample(2, size=50, replace=TRUE, prob=ratio)
sum(s[s==1]) + sum(s[s==2])
sum(s[s==1])/lenght(s)
sum(s[s==1])/length(s)
sum(s[s==2])/length(s)
ints > 5
m
m <- matrix(20,40)
m
m <- matrix(20:40)
m
m <- matrix(20:40, 1:10)
m
m <- matrix(1:60, ncol = 6)
m
m > 24
m[m > 24]
which(m>24)
which(m[m>24])
which(ints > 7)
any(m <0)
any(ints > 0)
any(ints < 0)
all(ints > 0)
require(readr)
library(readr)
df
tbl_df(data(iris))
iris
data.frame(iris)
data.frame(iris)
iris
ext_tracks_file <- paste0("http://rammb.cira.colostate.edu/research/",
"tropical_cyclones/tc_extended_best_track_dataset/",
"data/ebtrk_atlc_1988_2015.txt")
ext_tracks_widths <- c(7, 10, 2, 2, 3, 5, 5, 6, 4, 5, 4, 4, 5, 3, 4, 3, 3, 3,
4, 3, 3, 3, 4, 3, 3, 3, 2, 6, 1)
ext_tracks_colnames <- c("storm_id", "storm_name", "month", "day",
"hour", "year", "latitude", "longitude",
"max_wind", "min_pressure", "rad_max_wind",
"eye_diameter", "pressure_1", "pressure_2",
paste("radius_34", c("ne", "se", "sw", "nw"), sep = "_"),
paste("radius_50", c("ne", "se", "sw", "nw"), sep = "_"),
paste("radius_64", c("ne", "se", "sw", "nw"), sep = "_"),
"storm_type", "distance_to_land", "final")
ext_tracks <- read_fwf(ext_tracks_file,
fwf_widths(ext_tracks_widths, ext_tracks_colnames),
na = "-99")
print(datapath)
datafile <- file.path(datapath)
datafile <- file.path(datapath, "urban.csv.gz")
urban <- read_csv(datafile)
head(urban)
urban <- read_csv(datafile, col_types = cols(zcta=col_character())
)
urban <- read_csv(datafile, col_types = 'cccdc')
urban <- read_csv(datfile, col_skip(zcta5))
urban <- read_csv(datafile, col_skip(zcta5))
urban <- read_csv(datafile, col_skip=zcta5)
urban <- read_csv(datafile, col_types = col_skip("zcta5"))
urban <- read_csv(datafile, col_types = "zcta5")
urban <- read_csv(datafile, col_types = zcta5)
skip()
head(urban)
urban <- read_csv(datafile, col_types='cccd-', skip=1:100)
urban <- read_csv(datafile, col_types='cccd-', skip=c(1:100)
)
urban <- read_csv(datafile, col_types='cccd-', skip=100)
urban <- read_csv(datafile, col_types='cccd-', n_max=100)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
summary(worldcup)
table(worldcup$Team)
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
ls()
summary(ext_tracks)
ext_tracks %>%
summarize(n_obs = n(),
worst_wind = max(max_wind),
ext_tracks %>%
summarize(n_obs = n(),
worst_wind = max(max_wind),
worst_pressure = min(min_pressure))
worst_pressure = min(min_pressure)) %>%
ext_tracks %>%
summarize(n_obs = n(),
worst_wind = max(max_wind),
worst_pressure = min(min_pressure)) %>%
```
ext_tracks %>%
summarize(n_obs = n(),
worst_wind = max(max_wind),
worst_pressure = min(min_pressure))
ext_tracks %>%
summarize(n_obs=n(),
worst_winds = knots_to_mph(max(max_wind)),
worst_pressure = min(min_pressure),
}
knots_to_mph <- function(knots){
mph <- 1.152 * knots
}
ext_tracks %>%
summarize(n_obs=n(),
worst_winds = knots_to_mph(max(max_wind)),
worst_pressure = min(min_pressure))
```
ext_tracks %>%
group_by(storm_name, year) %>%
head()
ext_tracks %>%
group_by(storm_name, year) %>%
summarize(n_obs = n(),
worst_winds = knots_to_mph(max(max_wind)),
worst_pressue  = min(min_pressure))
ext_tracks %>%
group_by(storm_name) %>%
summarize(worst_wind = knots_to_mph(max(max_wind)) %>%
ggplot(aes(x = worst_wind)) + geom_histogram()
ext_tracks %>%
ext_tracks %>%
group_by(storm_name) %>%
summarize(worst_wind = knots_to_mph(max(max_wind))) %>%
ggplot(aes(x = worst_wind)) + geom_histogram()
ext_tracks %>%
select(storm_name, month, day, hour, year, latitude, longitude, max_wind)
ext_tracks %>%
select(storm_name, ends_with("itude"), starts_with("radius_34"))
ext_tracks %>%
select(storm_name, hour, max_wind) %>%
filter(hour == "00") %>%
head(3)
ext_tracks %>%
group_by(storm_name, year) %>%
summarize(worst_wind = max(max_wind)) %>%
filter(worst_wind >= 160)
ext_tracks %>%
group_by(storm_name, year) %>%
select(storm_name == "Andrew" & max_wind >= 137)
ext_tracks %>%
group_by(storm_name, year) %>%
filter(storm_name == "Andrew" & max_wind >= 137)
ext_tracks %>%
select(storm_name, month, day, hour, latitude, longitude, max_wind) %>%
filter(storm_name == "Andrew" & max_wind >= 137)
ext_tracks %>%
select(storm_name, month, day, hour, latitude, longitude, max_wind) %>%
filter(storm_name == "ANDREW" & max_wind >= 137)
worldcup <- worldcup %>%
mutate(player_name = rownames(worldcup))
slice(worldcup, 1:3)
worldcup %>% slice(1:3)
worldcup %>%
group_by(Position) %>%
mutate(ave_shots = mean(Shots)) %>%
ungroup()
worldcup %>%
rename(Name = player_name) %>%
slice(1:3)
data("VADeaths")
head(VADeaths)
VADeaths <- VADeaths %>%
tbl_df(VADeaths) %>%
mutate(age = row.names(VADeaths))
VADeaths <- VADeaths %>%
tbl_df() %>%
mutate(age = row.names(VADeaths))
head(VADeaths)
VADeaths <- VADeaths %>%
gather(key = key, value = death_rate, -age)
head(VADeaths)
worldcup %>%
select(Position, Time, Shots, Tackles, Saves) %>%
gather(Type, Number, -Position, -Time) %>%
ggplot(aes(x = Time, y = Nmber)) +
geom_point() +
facet_grid(Type ~ Position)
worldcup %>%
select(Position, Time, Shots, Tackles, Saves) %>%
gather(Type, Number, -Position, -Time) %>%
ggplot(aes(x = Time, y = Number)) +
geom_point() +
facet_grid(Type ~ Position)
worldcup %>%
select(Position, Time, Shots, Tackles, Saves) %>%
gather(Type, Number, -Position, -Time)
slice(1:10)
worldcup %>%
select(Position, Time, Shots, Tackles, Saves) %>%
gather(Type, Number, -Position, -Time) %>%
slice(1:10)
wc_table <- worldcup %>%
filter(Team %in% c("Spain", "Netherlands", "Uruguay", "Germany")) %>%
select(Team, Position, Passes) %>%
group_by(Team, Position) %>%
summarize(ave_passes = mean(Passes),
min_passes = min(Passes),
max_passes = max(Passes),
pass_summary = paste0(round(ave_passes), " (",
min_passes, ", ",
max_passes, ")")) %>%
select(Team, Position, pass_summary)
wc_table
wc_table %>%
spread(Position, pass_summary) %>%
kable()
wc_table %>%
spread(Position, pass_summary) %>%
table()
library(knitr)
wc_table %>%
spread(Position, pass_summary) %>%
kable()
wc_table
skip()
submit()
names(titanic)
submit()
submit()
submit()
vignette(dplyr)
vignette("dplyr")
vignette("tidyr")
skip()
skip()
paste("Square", "Circle", "Triangle")
paste("Square", "Circle", "Triangle", sep=+)
paste("Square", "Circle", "Triangle", sep="+")
paste0("Square", "Circle", "Triange")
s <- c("Square", "Circle", "Triangle")
paste(s)
s <- c("Square", "Circle", "Triangle")
paste(s)
paste("my favorites are", s)
paste("my favorites is a", s)
cities <- c("Tokyo", "London")
paste("The best city was", city, "the worst city was", city)
city<- c("Tokyo", "London")
paste("The best city was", city, "the worst city was", city)
paste("The", times," city was", city)
city <- c("Tokyo", "London")
times <- c('best', 'worst')
paste("The", times," city was", city)
paste0(c("Square", "Circle", "Triangle"), collapse=TRUE)
paste0(c("Square", "Circle", "Triangle"), collapse=" ")
regular_expression <- "a"
regular_expression2 <- "u"
string_to_search <- "Maryland"
# Searching
grepl(regular_expression, string_to_search)
grepl(regular_expression2, string_to_search)
state.name
head(state.name)
grepl(".", "Maryland")
grepl("\\w", "abcdefghijklmnopqrstuvwxyz0123456789")
grepl("[aeiou]", "rhythms")
grepl("[^aeiou]", "rhythms")
grepl("[a-i]", "rhythms")
grepl("[1-5]", "welcome2014-party")
start_end_vowel <- "^[AEIOU]{1}.+[aeiou]{1}$"
vowel_state_lgl <- grepl(start_end_vowel, state.name)
head(vowel_state_lgl)
state.name[vowel_state_lgl]
library(stringr)
require(stringr)
state_tbl <- paste(state.name, state.area, state.abb)
head(state_tbl)
str_order(state.name)
str_pad("Thai", width = 8, side = "left", pad = "-")
cat(str_wrap(pasted_states, width = 80))
cat(str_wrap(state.name, width = 80))
cat(str_wrap(state.name, width = 60))
cat(str_wrap(state.name, width = 40))
cat(str_wrap(state.name, width = 20))
cat(str_wrap(pasted_states, width = 20))
pasted_states <- paste(state.name[1:20], collapse = " ")
cat(str_wrap(pasted_states, width = 20))
cat(str_wrap(pasted_states, width = 80))
a_tale <- "It was the best of times it was the worst of times it was the age of wisdom it was the age of foolishness"
word(a_tale, 2)
word(a_tale, end = 3)
word(a_tale, start = 11, end =15)
require(pryr)
if (require(pryr) == FALSE) {install.packages("pryr")}
if (require(pryr) == FALSE) {install.packages("pryr");library(pryr)}
ls()
object.size(worldcup)
object_size(worldcup)
if (require(magrittr) == FALSE){install.packages("magrittr"); library(magrittr)}
?get
ls()[1]
get(ls()[1])
get(ls()[i])
1:length(s())
1:length(ls())
for(num in 1:length(ls())){
get(ls()[num])
}
for(num in 1:length(ls())){
print(get(ls()[num]))
}
for(i in 1:length(ls())){
}
print(get(ls()[i]))
for(i in 1:length(ls())){
print(get(ls()[i]))
}
sapply(ls(), function(x) object_size(get(x))) %>% sort %>%tail(5)
get(ls()[1])
object_size(get(ls()[1]))
names(sapply(ls(), function(x) object_size(get(x))) %>% sort %>%tail(5))
high_mem <- names(sapply(ls(), function(x) object_size(get(x))) %>% sort %>%tail(5))
sapply(rm(), high_mem)
high_mem <- names(sapply(ls(), function(x) object_size(get(x))) %>% sort %>%tail(5))
sapply(rm(), ls()[ls() == high_mem])
sapply(high_mem, rm())
?sapply
mem_change(rm(high_mem[1]))
high_mem[1]
class(high_mem[1])
mem_change(rm(get(high_mem[1]))
mem_change(rm(get(high_mem[1])))
mem_change(rm(get(high_mem[1])))
get(high_mem[1])
class(get(high_mem[1]))
rm(get(high_mem[1]))
rm(ls()[1])
ls()
rm("a_tale")
class(rm("a_tale"))
class("a_tale")
rm(high_mem[2])
rm(as.character(high_mem[2]))
mem_change(rm("worldcup"))
object_size(worldcup)
mem_change(rm(worldcup))
mem_change(rm("worldcup"))
ls()
mem_change(rm("titanic"))
ls()
data(titanic)
data("titanic")
data("Titanic")
object_size(Titanic)
mem_change(rm("Titanic"))
ls()
object_size(integer(0))
str(.Machine)
gc()
swirl()
grepl("[Ii]", c("HAwaii", "Illinois", "Kentucky"))
grepl("[Ii]", c("Hawaii", "Illinois", "Kentucky"))
grep("[Ii]", c("Hawaii", "Illinois", "Kentucky"))
sub("[Ii]", "1", c("Hawaii", "Illinois", "Kentucky"))
gsub("[Ii]", "1", c("Hawaii", "Illinois", "Kentucky"))
two_s <- state.name[grep("ss", state.name)]
two_s
strsplit(two_s, "ss")
str_extract("Camaro z28", "[0-9]+")
str_extract("Camaro Z28", "[0-9]+")
str_order(c("p", "e", 'n', 'g'))
str_pad("Thai", width=8, side='left', pad = '-')
str_to_title(c("CAPS", 'low', 'TitLE'))
str_to_title(c("CAPS", 'low', 'Title'))
str_trim(" trim me ")
word("See Spor run.", 2)
word("See Spot run.", 2)
swirl()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
ko2cfLo2WHQQSZBd
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
skip()
install.packages("tm")
install.packages("tm", dependencies = TRUE)
remove.packages("tm")
install.packages("tm", dependencies = TRUE)
library(tm)
install.packages(slam)
install.packages("slam")
install.packages("tm", dependencies = TRUE)
library(tm)
setwd("D:/Dropbox/Programming/Coursera_DataScience/3_GetAndCleanData/Worksamples/ExtractingPDFDocumentsFromWebpage")
?readPDF()
vignette(tm)
vignette('tm')
doc <- readPDF(control = list(text = "-layout"))(elem = list(uri = "./data/1.pdf"),
language = "en",
id = "id1")
doc
str(doc)
doc$content
names(doc)
pdf <- readPDF(PdftotextOptions = "-layout")
library(xpdf)
install.packages("xpdf")
install.packages("SnowballC")
install.package("Worcloud")
install.packages("Worcloud")
install.packages("Wordcloud")
install.packages("wordcloud")
